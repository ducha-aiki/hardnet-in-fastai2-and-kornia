{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/kornia/kornia@align_corners=False\n",
      "  Cloning https://github.com/kornia/kornia (to revision align_corners=False) to /tmp/pip-req-build-j_qmu_z2\n",
      "  Running command git clone -q https://github.com/kornia/kornia /tmp/pip-req-build-j_qmu_z2\n",
      "  Running command git checkout -b align_corners=False --track origin/align_corners=False\n",
      "  Switched to a new branch 'align_corners=False'\n",
      "  Branch align_corners=False set up to track remote branch align_corners=False from origin.\n",
      "Requirement already satisfied (use --upgrade to upgrade): kornia==0.2.0+cabdd68 from git+https://github.com/kornia/kornia@align_corners=False in /home/old-ufo/dev/fresh-kornia\n",
      "Requirement already satisfied: torch>=1.0.0 in /home/old-ufo/storage/anaconda3/envs/fastai2/lib/python3.7/site-packages (from kornia==0.2.0+cabdd68) (1.4.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/old-ufo/storage/anaconda3/envs/fastai2/lib/python3.7/site-packages (from kornia==0.2.0+cabdd68) (7.0.0)\n",
      "Building wheels for collected packages: kornia\n",
      "  Building wheel for kornia (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kornia: filename=kornia-0.2.0+cabdd68-py2.py3-none-any.whl size=147068 sha256=190b5f08030b238e330fee0c433b98af2ee08c1deabc61e8703fc2d8e4f785fb\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-jw6uz2h_/wheels/08/7e/79/0985a0e702fa8496fd528e669e2ee369290c998348c7474147\n",
      "Successfully built kornia\n",
      "Requirement already satisfied: pytorch_metric_learning in /home/old-ufo/storage/anaconda3/envs/fastai2/lib/python3.7/site-packages (0.9.81)\n",
      "Requirement already satisfied: tqdm in /home/old-ufo/storage/anaconda3/envs/fastai2/lib/python3.7/site-packages (from pytorch_metric_learning) (4.43.0)\n",
      "Requirement already satisfied: torch in /home/old-ufo/storage/anaconda3/envs/fastai2/lib/python3.7/site-packages (from pytorch_metric_learning) (1.4.0)\n",
      "Requirement already satisfied: numpy in /home/old-ufo/storage/anaconda3/envs/fastai2/lib/python3.7/site-packages (from pytorch_metric_learning) (1.18.2)\n",
      "Requirement already satisfied: scikit-learn in /home/old-ufo/storage/anaconda3/envs/fastai2/lib/python3.7/site-packages (from pytorch_metric_learning) (0.22.2.post1)\n",
      "Requirement already satisfied: torchvision in /home/old-ufo/storage/anaconda3/envs/fastai2/lib/python3.7/site-packages (from pytorch_metric_learning) (0.5.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/old-ufo/storage/anaconda3/envs/fastai2/lib/python3.7/site-packages (from scikit-learn->pytorch_metric_learning) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/old-ufo/storage/anaconda3/envs/fastai2/lib/python3.7/site-packages (from scikit-learn->pytorch_metric_learning) (1.4.1)\n",
      "Requirement already satisfied: six in /home/old-ufo/storage/anaconda3/envs/fastai2/lib/python3.7/site-packages (from torchvision->pytorch_metric_learning) (1.14.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/old-ufo/storage/anaconda3/envs/fastai2/lib/python3.7/site-packages (from torchvision->pytorch_metric_learning) (7.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/kornia/kornia@align_corners=False\n",
    "!pip install pytorch_metric_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import random\n",
    "import numpy as np\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "from fastai2.basics import *\n",
    "from fastcore import *\n",
    "from fastai2.vision.all import *\n",
    "from fastai2.callback.all import *\n",
    "from fastprogress import fastprogress\n",
    "from fastai2.callback.mixup import *\n",
    "from fastscript import *\n",
    "import torchvision as tv\n",
    "import kornia as K\n",
    "\n",
    "def imshow_torch(tensor, *kwargs):\n",
    "    plt.figure()\n",
    "    plt.imshow(K.tensor_to_image(tensor), *kwargs)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_name = 'liberty'\n",
    "val_ds_name = 'notredame'\n",
    "ds_root = '/home/old-ufo/storage/datasets/UBC-Phototour-Patches-Torch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will define modified dataset to match HardNet implementation.\n",
    "Specifically, it generates pairs of the same-class images for the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairPhotoTour(tv.datasets.PhotoTour):\n",
    "    \"\"\"\n",
    "    From the PhotoTour Dataset it generates pairs of same class in a batch\n",
    "    Based on code from https://github.com/vbalnt/tfeat\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 train_mode=True, # We need different behavoir for train and test mode\n",
    "                 bs = 1024, #batch size. There will be only 2 samples of same class in the batch.\n",
    "                 n_pairs = 1024*5000, #It is simple to have n_pairs to be divisible by bs\n",
    "                 *arg, **kw):\n",
    "        super(PairPhotoTour, self).__init__(*arg, **kw)\n",
    "        self.train_mode = train_mode\n",
    "        self.n_pairs = n_pairs\n",
    "        self.bs = bs\n",
    "        # Dict: indexes of the class samples by class label\n",
    "        self.indices_dict = self.create_indices(self.labels.numpy())\n",
    "        if self.train_mode:\n",
    "            self.generate_pairs()\n",
    "        return\n",
    "    \n",
    "    def create_indices(self, labels):\n",
    "        inds = dict()\n",
    "        for idx, ind in enumerate(labels):\n",
    "            if ind not in inds:\n",
    "                inds[ind] = []\n",
    "            inds[ind].append(idx)\n",
    "        return inds\n",
    "\n",
    "    def generate_pairs(self):\n",
    "        labels = self.labels\n",
    "        num_pairs = self.n_pairs\n",
    "        self.pairs = []\n",
    "        indices_dict = self.indices_dict\n",
    "        classes = np.unique(self.labels.numpy())\n",
    "        n_classes = classes.shape[0]\n",
    "        num_epochs = num_pairs // n_classes + 1\n",
    "        print('Generating {} pairs for training'.format(self.n_pairs))\n",
    "        for ep in progress_bar(range(num_epochs)):\n",
    "            classes_perm = np.random.permutation(classes)\n",
    "            for c in classes_perm:\n",
    "                samples_in_class = indices_dict[c]\n",
    "                if len(samples_in_class) > 2:\n",
    "                    random.shuffle(samples_in_class)\n",
    "                self.pairs.append([*samples_in_class[:2], c])\n",
    "        self.pairs = torch.LongTensor(self.pairs)[:num_pairs]\n",
    "        return \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if not self.train_mode:\n",
    "            m = self.matches[index]\n",
    "            img1 = self.data[m[0]]\n",
    "            img2 = self.data[m[1]]\n",
    "            # Output: two concatenated  an match/non-match label, as definited in Brown at.al 2010\n",
    "            return img1.unsqueeze(0), img2.unsqueeze(0), m[2] \n",
    "        t = self.pairs[index]\n",
    "        img_a, img_p, label = self.data[t[0]], self.data[t[1]], t[2]\n",
    "        # Output: two concatenated images of the same class and class label\n",
    "        return img_a.unsqueeze(0), img_p.unsqueeze(0), label\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train_mode:\n",
    "            return self.pairs.size(0)\n",
    "        else:\n",
    "            return self.matches.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do augmentation on GPU with [kornia](https://github.com/kornia/kornia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_size = 64\n",
    "out_size = 32\n",
    "sigma = orig_size / (2.*out_size)\n",
    "\n",
    "train_aug = nn.Sequential( \n",
    "    K.filters.GaussianBlur2d((7,7),(0.6,  0.6)), # Blur for proper downscale\n",
    "    torch.nn.ReplicationPad2d(8), # otherwise small black corners appear\n",
    "    K.augmentation.RandomAffine(degrees=(-5.0, 5.0),\n",
    "                                scale=(0.9, 1.0),\n",
    "                                shear=(5.0, 5.0),\n",
    "                                translate=(0.03, 0.03)),\n",
    "    K.augmentation.CenterCrop(orig_size),\n",
    "    K.Resize((out_size,out_size)))\n",
    "\n",
    "test_aug = nn.Sequential( \n",
    "    K.filters.GaussianBlur2d((7,7),(0.6,  0.6)), # Blur for proper downscale\n",
    "    K.Resize((out_size,out_size)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2  import *\n",
    "# We need to transform all images\n",
    "class TupleAug(ItemTransform):\n",
    "    def __init__(self, tfm):\n",
    "        self.tfm = tfm\n",
    "    def encodes(self, o): \n",
    "        out = []\n",
    "        with torch.no_grad():\n",
    "            for i,oi in enumerate(o):\n",
    "                if i < len(o) - 1:\n",
    "                    out.append(self.tfm(oi.float()))\n",
    "                else:\n",
    "                    out.append(oi)\n",
    "        return out\n",
    "class ReshapeTupleToBatch(ItemTransform):\n",
    "    def encodes(self, o): \n",
    "        return torch.cat(o[:-1],dim=0), o[-1].repeat(len(o)-1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchRandomFlip(ItemTransform):\n",
    "    def encodes(self, o): \n",
    "        mask = torch.randint_like(o[-1], 0,2) > 0\n",
    "        out = [] \n",
    "        with torch.no_grad():\n",
    "            for oi in o[:-1]:\n",
    "                out.append(oi)\n",
    "                out[-1].masked_scatter_(mask.view(-1,1,1,1), oi.flip(3))\n",
    "            mask2 = torch.randint_like(o[-1], 0,2) > 0\n",
    "            for i, oi in enumerate(out):\n",
    "                out[i].masked_scatter_(mask2.view(-1,1,1,1), oi[mask2].flip(3))\n",
    "        out.append(o[-1])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 5120000 pairs for training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='32' class='' max='32', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [32/32 00:15<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "BS = 1024\n",
    "TEST_BS = 128\n",
    "N_WORKERS = 4\n",
    "\n",
    "ds_train = PairPhotoTour(root=ds_root,\n",
    "                              name=train_ds_name,\n",
    "                              bs=BS,\n",
    "                              n_pairs=5000*BS,  \n",
    "                              train_mode=True)\n",
    "\n",
    "ds_val = PairPhotoTour(root=ds_root,\n",
    "                      name=val_ds_name,\n",
    "                      train_mode=False)\n",
    "\n",
    "dl_train = TfmdDL(ds_train,\n",
    "                 device=torch.device('cuda:0'),\n",
    "                 after_item=[ToTensor], \n",
    "                 after_batch=[TupleAug(train_aug), # augmening both patches in pair\n",
    "                              BatchRandomFlip,  # random flip\n",
    "                              ReshapeTupleToBatch], #two patches -> single tensor\n",
    "                 bs=BS, num_workers=N_WORKERS)\n",
    "\n",
    "dl_val = TfmdDL(ds_val,\n",
    "                 device=torch.device('cuda:0'),\n",
    "                 after_item=[ToTensor], \n",
    "                 after_batch=[TupleAug(test_aug), ReshapeTupleToBatch],\n",
    "                 bs=TEST_BS, num_workers=N_WORKERS)\n",
    "\n",
    "patches, labels  = dl_train.one_batch()\n",
    "\n",
    "imshow_torch(patches[0])\n",
    "imshow_torch(patches[0+BS])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define HardNet model\n",
    "(https://arxiv.org/pdf/1705.10872.pdf)\n",
    "\n",
    "![image.png](training-hardnet-in-fastai2-with-kornia-aug_files/att_00000.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#monkey patch (on my PC torch.qr outputs nans)\n",
    "def orthogonal_(tensor, gain=1):\n",
    "    r\"\"\"Fills the input `Tensor` with a (semi) orthogonal matrix, as\n",
    "    described in `Exact solutions to the nonlinear dynamics of learning in deep\n",
    "    linear neural networks` - Saxe, A. et al. (2013). The input tensor must have\n",
    "    at least 2 dimensions, and for tensors with more than 2 dimensions the\n",
    "    trailing dimensions are flattened.\n",
    "\n",
    "    Args:\n",
    "        tensor: an n-dimensional `torch.Tensor`, where :math:`n \\geq 2`\n",
    "        gain: optional scaling factor\n",
    "\n",
    "    Examples:\n",
    "        >>> w = torch.empty(3, 5)\n",
    "        >>> nn.init.orthogonal_(w)\n",
    "    \"\"\"\n",
    "    if tensor.ndimension() < 2:\n",
    "        raise ValueError(\"Only tensors with 2 or more dimensions are supported\")\n",
    "\n",
    "    rows = tensor.size(0)\n",
    "    cols = tensor.numel() // rows\n",
    "    flattened = tensor.new(rows, cols).normal_(0, 1)\n",
    "\n",
    "    if rows < cols:\n",
    "        flattened.t_()\n",
    "\n",
    "    # Compute the qr factorization\n",
    "    # Here is patch: use np.linalg.qr instead of torch.qr\n",
    "    q, r = np.linalg.qr(flattened)\n",
    "    r = torch.from_numpy(r)\n",
    "    q = torch.from_numpy(q)\n",
    "    # Make Q uniform according to https://arxiv.org/pdf/math-ph/0609050.pdf\n",
    "    d = torch.diag(r, 0)\n",
    "    ph = d.sign()\n",
    "    q *= ph\n",
    "\n",
    "    if rows < cols:\n",
    "        q.t_()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tensor.view_as(q).copy_(q)\n",
    "        tensor.mul_(gain)\n",
    "    return tensor\n",
    "torch.nn.init.orthogonal_ = orthogonal_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HardNet(nn.Module):\n",
    "    \"\"\"HardNet model definition\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(HardNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1, bias = False),\n",
    "            nn.BatchNorm2d(32, affine=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1, bias = False),\n",
    "            nn.BatchNorm2d(32, affine=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1, bias = False),\n",
    "            nn.BatchNorm2d(64, affine=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1, bias = False),\n",
    "            nn.BatchNorm2d(64, affine=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2,padding=1, bias = False),\n",
    "            nn.BatchNorm2d(128, affine=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1, bias = False),\n",
    "            nn.BatchNorm2d(128, affine=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv2d(128, 128, kernel_size=8, bias = False),\n",
    "            nn.BatchNorm2d(128, affine=False),\n",
    "            Flatten()\n",
    "        )\n",
    "        self.features.apply(self.weights_init)\n",
    "        return\n",
    "    def input_norm(self, x):\n",
    "        std, mean = torch.std_mean(x, dim=(2,3), keepdim=True)\n",
    "        return (x - mean) / (std + 1e-7)\n",
    "    def weights_init(self, m):\n",
    "        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "            nn.init.orthogonal_(m.weight.data, gain=0.6)\n",
    "            print (m.weight.sum())\n",
    "            try:\n",
    "                nn.init.constant_(m.bias.data, 0.01)\n",
    "            except: pass\n",
    "        return\n",
    "    def forward(self, input):\n",
    "        x = self.features(self.input_norm(input))\n",
    "        return F.normalize(x, p=2, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function: triplet margin loss with hard-in-batch mining.\n",
    "\n",
    "![image.png](training-hardnet-in-fastai2-with-kornia-aug_files/att_00001.png)\n",
    "\n",
    "We will use great repo by Kevin Musgrave.\n",
    "\n",
    "https://github.com/KevinMusgrave/pytorch-metric-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "from pytorch_metric_learning import losses, miners\n",
    "\n",
    "LossFn = losses.TripletMarginLoss(margin = 1.0)\n",
    "Miner = miners.BatchHardMiner()\n",
    "\n",
    "def loss_hard_triplet_margin(x, y):\n",
    "    hard_pairs = Miner(x, y)\n",
    "    loss = LossFn(x, y, hard_pairs)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation metric - False positive rate at recall = 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original FPR95\n",
    "def ErrorRateAt95Recall(distances, labels):\n",
    "    '''From https://github.com/DagnyT/hardnet/blob/master/code/EvalMetrics.py'''\n",
    "    recall_point = 0.95\n",
    "    labels = labels[np.argsort(distances)]\n",
    "    # Sliding threshold: get first index where recall >= recall_point. \n",
    "    # This is the index where the number of elements with label==1 below the threshold reaches a fraction of \n",
    "    # 'recall_point' of the total number of elements with label==1. \n",
    "    # (np.argmax returns the first occurrence of a '1' in a bool array). \n",
    "    threshold_index = np.argmax(np.cumsum(labels) >= recall_point * np.sum(labels)) \n",
    "    FP = np.sum(labels[:threshold_index] == 0) # Below threshold (i.e., labelled positive), but should be negative\n",
    "    TN = np.sum(labels[threshold_index:] == 0) # Above threshold (i.e., labelled negative), and should be negative\n",
    "    return float(FP) / float(FP + TN)\n",
    "\n",
    "\n",
    "class FPR95(Metric):\n",
    "    \"Average the values of `func` taking into account potential different batch sizes\"\n",
    "    def reset(self):           self.dists, self.labels = [], []\n",
    "    def accumulate(self, learn):\n",
    "        x = learn.pred\n",
    "        N = x.size(0)\n",
    "        assert N % 2 == 0\n",
    "        N_2 = N // 2\n",
    "        targ = learn.yb[0][:N_2]\n",
    "        with torch.no_grad():\n",
    "            dist = torch.norm(x[:N_2]-x[N_2:],p=2,dim=1)\n",
    "        self.dists.append(dist.cpu().detach().view(-1))\n",
    "        self.labels.append(targ.cpu().detach().view(-1))\n",
    "        return\n",
    "    @property\n",
    "    def value(self):\n",
    "        if len(self.dists) == 0: return\n",
    "        if len(self.labels) == 0: return\n",
    "        dists = torch.cat(self.dists, dim=0)\n",
    "        labels = torch.cat(self.labels, dim=0)\n",
    "        return ErrorRateAt95Recall(dists.detach().cpu().view(-1).numpy(), labels.detach().cpu().view(-1).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original implementation regenerates random pairs before each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegeneratePairs(Callback):\n",
    "    def begin_train(self):\n",
    "        if learn.training and learn.epoch > 0:\n",
    "            learn.dls.train_ds.generate_pairs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original paper uses SGD with momentum and dampening. We will give a shot with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.6598, grad_fn=<SumBackward0>)\n",
      "tensor(-4.2974, grad_fn=<SumBackward0>)\n",
      "tensor(2.2643, grad_fn=<SumBackward0>)\n",
      "tensor(-0.4888, grad_fn=<SumBackward0>)\n",
      "tensor(-8.6757, grad_fn=<SumBackward0>)\n",
      "tensor(-1.3346, grad_fn=<SumBackward0>)\n",
      "tensor(0.2649, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "data = DataLoaders(dl_train, dl_val).cuda()\n",
    "model = HardNet()\n",
    "learn = Learner(data, model,\n",
    "                loss_func=loss_hard_triplet_margin,\n",
    "                metrics=[FPR95()], cbs=[RegeneratePairs()],\n",
    "                wd=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>fpr95</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.931707</td>\n",
       "      <td>1.531047</td>\n",
       "      <td>0.011140</td>\n",
       "      <td>23:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.927906</td>\n",
       "      <td>1.527577</td>\n",
       "      <td>0.011140</td>\n",
       "      <td>23:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.928431</td>\n",
       "      <td>1.518422</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>23:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.925210</td>\n",
       "      <td>1.534905</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>23:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.920034</td>\n",
       "      <td>1.519193</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>23:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.914542</td>\n",
       "      <td>1.520321</td>\n",
       "      <td>0.010640</td>\n",
       "      <td>23:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.908269</td>\n",
       "      <td>1.513802</td>\n",
       "      <td>0.009660</td>\n",
       "      <td>23:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.895341</td>\n",
       "      <td>1.503396</td>\n",
       "      <td>0.005860</td>\n",
       "      <td>23:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.884706</td>\n",
       "      <td>1.500254</td>\n",
       "      <td>0.006120</td>\n",
       "      <td>23:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.878264</td>\n",
       "      <td>1.496547</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>23:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 5120000 pairs for training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='32' class='' max='32', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [32/32 00:13<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 5120000 pairs for training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='32' class='' max='32', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [32/32 00:13<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 5120000 pairs for training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='32' class='' max='32', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [32/32 00:13<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 5120000 pairs for training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='32' class='' max='32', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [32/32 00:14<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 5120000 pairs for training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='32' class='' max='32', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [32/32 00:13<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 5120000 pairs for training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='32' class='' max='32', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [32/32 00:13<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 5120000 pairs for training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='32' class='' max='32', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [32/32 00:13<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 5120000 pairs for training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='32' class='' max='32', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [32/32 00:14<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 5120000 pairs for training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='32' class='' max='32', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [32/32 00:12<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, 10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all. Now we can save our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('HardNetLib_fastai2KorniaAug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
